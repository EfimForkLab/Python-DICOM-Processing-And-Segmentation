{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 3 - Vorverarbeitung und 3D-Visualisierung - MUSTERLÖSUNG\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Efim Shliamin\n",
    "<br>\n",
    "**Matr.-Nr.:** 573270\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bearbeitungszeitraum\n",
    "\n",
    "**Bearbeitungsbegin:** Montag, 19.12.2022\n",
    "<br>\n",
    "**Abgabe:** Fr, 10.02.2023, 23:59 Uhr\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabenbeschreibung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse von tomographischen Bildgebungsverfahren (z.B. Computertomographie, Magnetresonanztomographie oder Positronen-Emissionstomographie) sind Stapel von z.T. mehreren hundert Schnitt-/Schichtbildern primär in der Transversalebene.\n",
    "Aus diesen *Originalbildern* können weitere Ebenen für eine Visualisierung berechnet werden. Der Bildstapel einer Ebene kann jedoch auch Basis einer 3D-Visualisierung sein.\n",
    "\n",
    "Innerhalb dieser Übung sollen zwei Ziele erreicht werden:\n",
    "1. Verarbeitung der einzelnen Schichtbilder als Vorbereitung einer 3D-Rekonstruktion\n",
    "2. Rekonstruktion und Visualisierung eines 3D-Modells auf Basis eines Bildstapels \n",
    "\n",
    "Der in dieser Übung zu verwendenden Bildstapel entstammt folgendem Link: <https://mri.radiology.uiowa.edu/VHDicom/VHFCT1mm/VHF-Head.tar.gz>\n",
    "\n",
    "**Wichtig:**\n",
    "- Der oben genannte Link ist zum Zeitpunkt der Ausgabe der Übungsaufgabe nicht erreichbar!\n",
    "- Verwenden Sie den Link in Aufgabe 2 aus Moodle! \n",
    "\n",
    "Der Datensatz ist den *CT Datasets (Visible Female CT Datasets)* des *Visible Human Project* (<https://www.nlm.nih.gov/research/visible/visible_human.html>) entnommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wichtige Hinweise zur Übung\n",
    "\n",
    "- Für die Realisierung von **Aufgabe 4** sind externe Bibliotheken sowie andere Programmiersprachen (Code außerhalb des Notebooks) ausdrücklich zugelassen.\n",
    "- Sollten Sie Bibliotheken verwenden, die sich nicht mit `pip` intallieren lassen bzw. externe Abhängigkeiten haben (z.B. VTK) oder eine andere Programmiersprache verwenden müssen Sie Ihre Lösung vorstellen:\n",
    "- Abgabe mit externen Komponenten:\n",
    "    - Zip-Archiv mit\n",
    "        - Notebook\n",
    "        - externer Quellcode\n",
    "        - Bild(er) Ihrer 3D-Rekonstruktion\n",
    "    - Vorstellung:\n",
    "      - Während der Übung bzw. zu einem vereinbarten Termin **vor dem Abgabedatum**\n",
    "      - Video / Screencast: Zeigen Sie, dass Ihr abgegebener Code die abgegebenen Bilder erzeugt\n",
    "        - Software für Screencasts wäre z.B. OBS (Open Broadcast Software, https://obsproject.com/de)\n",
    "        - Der Screencast soll über die Mediathek der HTW bereitgestellt werden\n",
    "        - Video kann auf versteckt gestellt werden, Link zum Video in Ihrem Notebook, oder Textdatei der Abgabe\n",
    "      - Sollte keine Vorstellung erfolgen, werden nur die über Moodle abgegebenen und mit den *Standard-Paketen* bzw. nachinstallierbaren Paketen ausführbaren Teile Ihrer Lösung bewertet.\n",
    "\n",
    "**Generelle Hinweise zur Bearbeitung:** \n",
    "\n",
    "Für die Visualisierung der **Aufgaben 1. - 3.** soll das `matplotlib`-Paket verwendet werden. Alle Bilder sollen *inline* in diesem Notebook ausgegeben werden.\n",
    "\n",
    "**Weitere Hinweise zur Abgabe**\n",
    "\n",
    "- Füllen Sie unbedingt die erste Zelle unterhalb der Überschrift mit Name und Matr.-Nr. aus!\n",
    "- Ergänzen Sie den Dateinamen des Notebooks vor der Abgabe um `_` und Ihre Matr.-Nr. (`Uebung 3 - 3D-Visualisierung_s0500000.ipynb`)\n",
    "- Setzen Sie vor der Abgabe den Kernel zurück und testen Sie, ob Sie Ihr Notebook vollständig ausführen können!\n",
    "- Entfernen Sie vor dem Upload alle Ausgaben aus dem Notebook!\n",
    "- Der verwendete Bildstapel muss nicht abgegeben werden.\n",
    "\n",
    "**Hinweise zur Benotung**\n",
    "\n",
    "- Die Aufgabe wird nach dem üblichen Notenschema von 1,0 bis 5,0 bewertet.\n",
    "- Diese Aufgabe wird mit 45% in der Gesamtnote der Übung gewichtet.\n",
    "\n",
    "### Viel Erfolg!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgaben:\n",
    "\n",
    "**1. Einlesen und Visualisieren des DICOM-Bildstapels**\n",
    "\n",
    "Lesen Sie alle DICOM-Bilder des Daten-Verzeichnisses ein.\n",
    "\n",
    "Visualisieren Sie den Bildstapel mit Hilfe eines interaktiven **Sliders** über den durch den Bildstapel navigiert werden kann. \n",
    "\n",
    "**Hinweise:**\n",
    "- Für **alle Plots** dieses Notebooks gilt:\n",
    "  - Colormap: `gray`\n",
    "  - Ausblenden der Achsenbeschriftungen\n",
    "- Verwenden Sie die Ihnen bekannte Bibliothek `pydicom` zum Einlesen der DICOM-Dateien.\n",
    "- Nutzen sie das Paket `ipywidgets` zur Realisierung der interaktiven Elemente.\n",
    "- Achten Sie beim Umgang mit Dateien und Verzeichnissen darauf, dass nicht immer nach Dateinamen sortierte Listen zurückgegeben werden.\n",
    "- Bringen Sie den Bildstapel am Besten schon anhand der Dateinamen in eine sinnvolle Reihenfolge\n",
    "  - Die Bilder innerhalb des Stapels sind von unten (Teil des oberen Brustkorbs) nach oben (Schädeldecke) über die Dateinamen sortiert (kleine Nummern liegen im Stapel unten, große Nummern oben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots werden inline im Notebook angezeigt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============\n",
    "GETTING READY\n",
    "=============\n",
    "\"\"\"\n",
    "\n",
    "# pip install pydicom\n",
    "\n",
    "# To perform 3D plotting, we are using the free version of plot.ly in offline mode \n",
    "# which uses WebGL to make visualization interactive. \n",
    "# plotly and scikit-image can be installed using conda:\n",
    "\n",
    "# conda install plotly\n",
    "# conda install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============\n",
    "IMPORT PACKAGES\n",
    "===============\n",
    "\"\"\"\n",
    "\n",
    "from pydicom import dcmread\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_file\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from glob import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from scipy import ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import *\n",
    "init_notebook_mode(connected=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================\n",
    "READING AND VISUALISING THE DICOM IMAGE STACK\n",
    "=============================================\n",
    "\"\"\"\n",
    "\n",
    "def navigation(index):       \n",
    "    ds = dcmread(\"head/vhf.\"+str(index)+\".dcm\")\n",
    "    arr = ds.pixel_array\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    text = fig.text(0.13, 1.0, f'Patient’s Name...: {ds.PatientName}'\n",
    "                           f'\\nPatient ID............: {ds.PatientID}'\n",
    "                           f'\\nModality..............: {ds.Modality}'\n",
    "                           f'\\nStudy Date.........: {ds.StudyDate}'\n",
    "                           f'\\nImage size..........: {ds.Rows} x {ds.Columns}'\n",
    "                           f'\\nPixel Spacing......: {ds.PixelSpacing}',\n",
    "                ha='left', va='center', size=10)\n",
    "    plt.imshow(arr, cmap=\"gray\")\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.tick_params(labelleft=False)\n",
    "    plt.show()\n",
    "    \n",
    "interact(navigation, index=widgets.IntSlider(min=1501, max=1734, step=1, value=1501), description='Index:', continuous_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Konvertierung des DICOM-Bildstapels in Binärbilder**\n",
    "\n",
    "Implementieren sie eine Funktion zur Konvertierung eines Bildes in das Binärformat anhand eines gegebenen Schwellenwertes.\n",
    "\n",
    "In CT-DICOM-Bildern zeichnen sich die Bereiche des Untersuchungsobjektes über vergleichsweise hohe Signalwerte aus. In Gegensatz dazu ist der Hintergrund durch niedrige Signalwerte gekennzeichnet. Mit Hilfe der binären Konvertierung kann das Objekt vom Hintergrund getrennt werden.\n",
    "\n",
    "Ihre Funktion soll die Pixel des Bildes anhand eines Vergleichs mit einem gegebenen Schwellenwert (Funktionsparameter) dem Hintergrund bzw. dem Objekt zuordnen:\n",
    "- Pixelwert < Schwellenwert: Pixel ist Hintergrundpixel\n",
    "- Pixelwert >= Schwellenwert: Pixel ist Objektpixel\n",
    "\n",
    "Ihre Funktion soll auf den in den Dateien gespeicherten Werten arbeiten (**keine** Konvertierung in HU).\n",
    "\n",
    "Wenden Sie Ihre Funktion auf alle Bilder des Stapels an. Wählen Sie hierzu einen Schwellenwert von **250**.\n",
    "\n",
    "Visualisieren Sie den konvertierten Bilderstapel analog zu **1.** (der Hintergrund soll in **schwarz**, das Objekt in **weiß** dargestellt werden).\n",
    "\n",
    "**Hinweis:**\n",
    "- Wenn Sie zur Optimierung Ihrer 3D-Rekonstruktion den Schwellenwert für die Binarisierung angepasst haben, vermerken Sie dies kurz (z.B. als Kommentar bei der Definition der Konstanten: `threshold=X # Besser für 3D-Rekonstruktion in 4.`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "======================================================\n",
    "CONVERSION OF THE DICOM IMAGE STACK INTO BINARY IMAGES\n",
    "======================================================\n",
    "\"\"\"\n",
    "\n",
    "def navigation_binarized(index):       \n",
    "    ds = dcmread(\"head/vhf.\"+str(index)+\".dcm\")\n",
    "    arr = ds.pixel_array\n",
    "    \n",
    "    # specify a threshold 0-255\n",
    "    threshold = 250\n",
    "\n",
    "    # make all pixels < threshold black\n",
    "    binarized = 1.0 * (arr > threshold)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    text = fig.text(0.13, 1.0, f'Patient’s Name...: {ds.PatientName}'\n",
    "                           f'\\nPatient ID............: {ds.PatientID}'\n",
    "                           f'\\nModality..............: {ds.Modality}'\n",
    "                           f'\\nStudy Date.........: {ds.StudyDate}'\n",
    "                           f'\\nImage size..........: {ds.Rows} x {ds.Columns}'\n",
    "                           f'\\nPixel Spacing......: {ds.PixelSpacing}',\n",
    "                ha='left', va='center', size=10)\n",
    "    plt.imshow(binarized, cmap=\"gray\")\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.tick_params(labelleft=False)\n",
    "    plt.show()\n",
    "    \n",
    "interact(navigation_binarized, index=widgets.IntSlider(min=1501, max=1734, step=1, value=1501), description='Index:', continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Optimieren der Binärbilder**\n",
    "\n",
    "Anhand der Visualisierung in **2.** ist zu erkennen, dass die Bilder z.T. kleine Artefakte im Hintergrund bzw. *Löcher* innerhalb des Objektes aufweisen. Der Objektrand ist teilweise sehr *ausgefranst*. Auf einigen Bildern sind Bereiche des Untersuchungstisches im Bild vorhanden.\n",
    "\n",
    "Versuchen Sie diese *ungünstigen* Eigenschaften der Bilder auszugleichen.\n",
    "\n",
    "Realisieren Sie zur Optimierung der Binärbilder die folgenden beiden Einzeloperationen:\n",
    "\n",
    "1. Definieren eines **globalen** Objektbereichs über ein Rechteck.\n",
    "    - Alle Pixel außerhalb dieses Objektbereiches sind automatisch Hintergrund\n",
    "    - Wenden Sie den von Ihnen definierten Objektbereich auf alle Bilder des Stapels an\n",
    "      - kann z.B. mittels Slicing realisiert werden\n",
    "    - Beispiel:\n",
    "    ```\n",
    "    x_left = 60\n",
    "    y_upper = 120\n",
    "    width = 400\n",
    "    height = 250\n",
    "    ```\n",
    "2. Morphologische Operationen (Erosion, Dilatation, Öffnung, Schließung) zur leichten Glättung der Objektränder, Schließung kleinerer Löcher im Objekt oder Entfernung kleinerer Artefakte\n",
    "    - Achten Sie auf die Reihenfolge der Operationen und deren Kombinationsmöglichkeiten\n",
    "    - Seien Sie mit diesen Operatoren vorsichtig. Bei übertriebener Anwendung gehen viele markante Konturinformnationen verloren \n",
    "\n",
    "Visualisieren Sie den optimierten Binärbildstapel analog zu **1.**\n",
    "\n",
    "**Hinweise:**\n",
    "- Die morphologische Operationen sind in den bereits installierten *Standard-Paketen* enthalten und sollten verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============================\n",
    "OPTIMIZING THE BINARY IMAGES\n",
    "============================\n",
    "\"\"\"\n",
    "\n",
    "def navigation_binarized_and_optimized(index):       \n",
    "    ds = dcmread(\"head/vhf.\"+str(index)+\".dcm\")\n",
    "    arr = ds.pixel_array\n",
    "    \n",
    "    # specify a threshold 0-255:\n",
    "    threshold = 250\n",
    "\n",
    "    # make all pixels < threshold black:\n",
    "    binarized = 1.0 * (arr > threshold)\n",
    "    \n",
    "    # to portion:\n",
    "    portion = binarized[20:340, 40:450]\n",
    "    \n",
    "    # optimizing:\n",
    "    opened = ndimage.binary_opening(portion)\n",
    "    eroded = ndimage.binary_erosion(opened)\n",
    "    closed = ndimage.binary_closing(eroded)\n",
    "    dilationed = ndimage.binary_dilation(closed)\n",
    "    \n",
    "    # plotting:\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    text = fig.text(0.13, 1.0, f'Patient’s Name...: {ds.PatientName}'\n",
    "                           f'\\nPatient ID............: {ds.PatientID}'\n",
    "                           f'\\nModality..............: {ds.Modality}'\n",
    "                           f'\\nStudy Date.........: {ds.StudyDate}'\n",
    "                           f'\\nImage size..........: {ds.Rows} x {ds.Columns}'\n",
    "                           f'\\nPixel Spacing......: {ds.PixelSpacing}',\n",
    "                ha='left', va='center', size=10)\n",
    "    plt.imshow(dilationed, cmap=\"gray\")\n",
    "    plt.tick_params(labelbottom=False)\n",
    "    plt.tick_params(labelleft=False)\n",
    "    plt.show()\n",
    "    \n",
    "interact(navigation_binarized_and_optimized, index=widgets.IntSlider(min=1501, max=1734, step=1, value=1501), description='Index:', continuous_update=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 3D-Rekonstruktion**\n",
    "\n",
    "Basierend auf den Binärbildern aus **3.** sollen Sie ein 3D-Modell des Datensatzes rekonstruieren.\n",
    "\n",
    "Grundsätzlich stehen für eine Rekonstruktion verschiedene Ansätze zur Auswahl, u.a.:\n",
    "- Triangulation der Oberfläche (Bildung von Dreiecken): [https://matplotlib.org/stable/gallery/mplot3d/trisurf3d_2.html](https://matplotlib.org/stable/gallery/mplot3d/trisurf3d_2.html)\n",
    "- Anwendung des Marching-Cubes-Algorithmus [https://scikit-image.org/docs/dev/auto_examples/edges/plot_marching_cubes.html](https://scikit-image.org/docs/dev/auto_examples/edges/plot_marching_cubes.html)\n",
    "- Konstruktion eines Volumenmodells aus den Objektvoxeln der gestapelten Schichten: [https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html](https://matplotlib.org/stable/gallery/mplot3d/scatter3d.html)\n",
    "\n",
    "Der Ansatz sowie die verwendeten Bibliotheken, die/den Sie verfolgen/verwenden wollen, bleibt Ihnen überlassen.\n",
    "\n",
    "Ihr Ergebnis sollen Sie als 3D-Plot visualisieren:\n",
    "- Ein *statisches* Perspektivbild (leichte Neigung auf allen Achsen) reicht hierfür aus (dies ist für einen 3D-Plot meist der Standard)\n",
    "- Formatieren Sie Ihren Plot so, dass die Achsen die korrekten Abmessungen / Skalierungen aufweisen\n",
    "  - Der Abstand auf der x- und y-Achse innerhalb eine CT-Scheibe beträgt 1 mm\n",
    "  - Der Abstand zwischen den CT-Scheiben beträgt ebenfalls 1 mm\n",
    "- Formatieren Sie Ihren Plot so, dass erkennbar ist, dass es sich um eine 3-dimensionale Darstellung handelt (z.B. über Transparenz, Gitterlinien, ...)\n",
    "\n",
    "**Hinweise:**\n",
    "\n",
    "- Berücksichtigen Sie die Reihenfolge der Bilder Ihres Bildstapels in Ihrer Rekonstruktion (der Kopf soll im 3D-Modell oben sein).\n",
    "- Sie können zur Optimierung Ihrer 3D-Rekonstruktion den in **Aufgabe 2** verwendeten Schwellenwert für die Binarisierung anpassen. Vermerken Sie dies dort!\n",
    "- Je nach verwendeter Bibliothek für die Rekonstruktion kann es möglich sein, dass die Visualisierung nicht mittels `matplotlib` im Notebook umgesetzt werden kann. Sollten Sie eine andere Bibliothek für die Visualisierung innerhalb des Notebooks verwenden, vermerken Sie dies.\n",
    "- Visualisierungen mittels externer Bibliotheken müssen als Bilddatei mit abgegeben werden. Erstellen Sie hierzu ein Zip-Archiv aus Notebook, Bilddateien und Quellcode sowie ggf. einem Link auf ein Video / einen Screencast.\n",
    "- Viele externe Bibliotheken bieten reichhaltige Funktionen zur Optimierung der Bilddaten vor einer 3D-Rekonstruktion an. Alternativ zur Nutzung der Ergebnisse aus **Aufgabe 3** können Sie eine komplette Vorverarbeitung mithilfe externer Bibliotheken als Input für eine 3D-Rekonstruktion nutzen.\n",
    "    - **Dies ersetzt jedoch nicht die Bearbeitung und Abgabe der Aufgaben 1 - 3 innerhalb des Notebooks!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==============\n",
    "LOAD CT SLICES\n",
    "==============\n",
    "\"\"\"\n",
    "\n",
    "# load the DICOM files\n",
    "files = []\n",
    "for index in range(1501, 1735):\n",
    "    files.append(pydicom.dcmread(\"head/vhf.\"+str(index)+\".dcm\"))\n",
    "    ds = dcmread(\"head/vhf.\"+str(index)+\".dcm\")\n",
    "    print(\"loading: {}\".format(index)) \n",
    "            \n",
    "\n",
    "print(\"file count: {}\".format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=======================================\n",
    "PLOT AXIAL, SAGITTAL AND CORONAL IMAGES \n",
    "=======================================\n",
    "\"\"\"\n",
    "\n",
    "# pixel aspects, assuming all slices are the same\n",
    "ps = files[0].PixelSpacing\n",
    "ss = files[0].SliceThickness\n",
    "ax_aspect = ps[1]/ps[0]\n",
    "sag_aspect = ps[1]/ss\n",
    "cor_aspect = ss/ps[0]\n",
    "\n",
    "# create 3D array\n",
    "img_shape = list(files[0].pixel_array.shape)\n",
    "img_shape.append(len(files))\n",
    "img3d = np.zeros(img_shape)\n",
    "\n",
    "# fill 3D array with the images from the files\n",
    "for i, s in enumerate(files):\n",
    "    img2d = s.pixel_array\n",
    "    img3d[:, :, i] = img2d\n",
    "\n",
    "# plot 3 orthogonal slices\n",
    "a1 = plt.subplot(2, 2, 1)\n",
    "plt.imshow(img3d[:, :, img_shape[2]//2])\n",
    "a1.set_aspect(ax_aspect)\n",
    "\n",
    "a2 = plt.subplot(2, 2, 2)\n",
    "plt.imshow(img3d[:, img_shape[1]//2, :])\n",
    "a2.set_aspect(sag_aspect)\n",
    "\n",
    "a3 = plt.subplot(2, 2, 3)\n",
    "plt.imshow(img3d[img_shape[0]//2, :, :].T)\n",
    "a3.set_aspect(cor_aspect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================\n",
    "SPECIFY THE PATH \n",
    "================\n",
    "\"\"\"\n",
    "\n",
    "data_path = \"Head/\"\n",
    "output_path = working_path = \"Save/\"\n",
    "g = glob(data_path + '/*.dcm')\n",
    "\n",
    "# Print out the first 5 file names to verify we're in the right folder.\n",
    "print (\"Total of %d DICOM images.\\nFirst 5 filenames:\" % len(g))\n",
    "print ('\\n'.join(g[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============\n",
    "HELPER FUNCTION \n",
    "===============\n",
    "\"\"\"\n",
    "\n",
    "# load_scan will load all DICOM images from a folder into a list for manipulation:\n",
    "def load_scan(path):\n",
    "    slices = [pydicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================\n",
    "HOUNDSFELD UNITS \n",
    "================\n",
    "\"\"\"\n",
    "\n",
    "# The voxel values in the images are raw.  get_pixels_hu converts raw values into Houndsfeld units\n",
    "def get_pixels_hu(scans):\n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 1\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = scans[0].RescaleIntercept\n",
    "    slope = scans[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===================\n",
    "LET'S LOAD THE DATA \n",
    "===================\n",
    "\"\"\"\n",
    "\n",
    "id=0\n",
    "patient = load_scan(data_path)\n",
    "imgs = get_pixels_hu(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========================\n",
    "LET'S SAVE THE NEW DATA SET \n",
    "===========================\n",
    "\"\"\"\n",
    "\n",
    "np.save(output_path + \"fullimages_%d.npy\" % (id), imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===============================================================\n",
    "LET'S NOW CREATE A HISTOGRAM OF ALL THE VOXEL DATA IN THE STUDY \n",
    "===============================================================\n",
    "\"\"\"\n",
    "\n",
    "file_used=output_path+\"fullimages_%d.npy\" % id\n",
    "imgs_to_process = np.load(file_used).astype(np.float64) \n",
    "\n",
    "plt.hist(imgs_to_process.flatten(), bins=50, color='c')\n",
    "plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========================\n",
    "CRITIQUING THE HISTOGRAM \n",
    "========================\n",
    "\n",
    "for reference (from Wikipedia):\n",
    "\n",
    "SUBSTANCE ---  HU\n",
    "air ---- -1000\n",
    "lung --- -500\n",
    "fat --- -100 to -50\n",
    "water --- 0\n",
    "blood --- +30 to +70\n",
    "muscle --- +10 to +40\n",
    "liver --- +40 to +60\n",
    "bone --- +700 to +3000\n",
    "\n",
    "\n",
    "---> Our histogram suggests the following:\n",
    "- There is lots of air\n",
    "- There's also some fat (brain)\n",
    "- There's an abundance of water\n",
    "- There is only a small bit of bone (seen as a tiny sliver of height between 1200-1700)\n",
    "\n",
    "---> This observation means that we will need to do significant preprocessing \n",
    "if we want to process the 3D-visualisation of the skeleton \n",
    "because only a tiny bit of the voxels represent bone.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=========================\n",
    "DISPLAYING AN IMAGE STACK \n",
    "=========================\n",
    "\"\"\"\n",
    "\n",
    "id = 0\n",
    "imgs_to_process = np.load(output_path+'fullimages_{}.npy'.format(id))\n",
    "\n",
    "def sample_stack(stack, rows=6, cols=6, start_with=10, show_every=3):\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=[12,12])\n",
    "    for i in range(rows*cols):\n",
    "        ind = start_with + i*show_every\n",
    "        ax[int(i/rows),int(i % rows)].set_title('slice %d' % ind)\n",
    "        ax[int(i/rows),int(i % rows)].imshow(stack[ind],cmap='gray')\n",
    "        ax[int(i/rows),int(i % rows)].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_stack(imgs_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==========\n",
    "RESAMPLING \n",
    "==========\n",
    "\n",
    "Although we have each individual slices, it is not immediately clear how thick each slice is.\n",
    "Fortunately, this is in the DICOM header.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Slice Thickness: %f\" % patient[0].SliceThickness)\n",
    "print(\"Pixel Spacing (row, col): (%f, %f) \" % (patient[0].PixelSpacing[0], patient[0].PixelSpacing[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This means we have 1.0 mm slices, and each voxel represents 1.0 mm.\n",
    "\n",
    "Because a CT slice is typically reconstructed at 512 x 512 voxels, \n",
    "each slice represents approximately 512 mm of data in length and width.\n",
    "\n",
    "Using the metadata from the DICOM we can figure out the size of each voxel as the slice thickness. \n",
    "In order to display the CT in 3D isometric form (which we will do below), \n",
    "and also to compare between different scans, \n",
    "it would be useful to ensure that each slice is resampled in 1x1x1 mm pixels and slices.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================\n",
    "SHAPE BEFORE VS AFTER RESAMPLING \n",
    "================================\n",
    "\"\"\"\n",
    "\n",
    "id = 0\n",
    "imgs_to_process = np.load(output_path+'fullimages_{}.npy'.format(id))\n",
    "def resample(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = map(float, ([scan[0].SliceThickness] + list(scan[0].PixelSpacing)))\n",
    "    spacing = np.array(list(spacing))\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor)\n",
    "    \n",
    "    return image, new_spacing\n",
    "\n",
    "print(\"Shape before resampling\\t\", imgs_to_process.shape)\n",
    "imgs_after_resamp, spacing = resample(imgs_to_process, patient, [1,1,1])\n",
    "print(\"Shape after resampling\\t\", imgs_after_resamp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========\n",
    "3D PLOTTING \n",
    "===========\n",
    "\n",
    "---> For kicks, we'll focus on rendering just THE BONES.\n",
    "---> Create a high-quality static using 3D capability of matplotlib\n",
    "---> Create a lower-quality but interactive render using plotly, which has WebGL support via JavaScript.\n",
    "---> The marching cubes algorithm is used to generate a 3D mesh from the dataset. \n",
    "The plotly model will utilize a higher step_size with lower voxel threshold to avoid overwhelming the web browser.\n",
    "\"\"\"\n",
    "\n",
    "def make_mesh(image, threshold=-300, step_size=1):\n",
    "\n",
    "    print(\"Transposing surface\")\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    print(\"Calculating surface\")\n",
    "    verts, faces, norm, val = measure.marching_cubes(p, threshold, step_size=step_size, allow_degenerate=True) \n",
    "    return verts, faces\n",
    "\n",
    "def plotly_3d(verts, faces):\n",
    "    x,y,z = zip(*verts) \n",
    "    print(\"Drawing\")\n",
    "    colormap=['rgb(236, 236, 212)','rgb(236, 236, 212)']\n",
    "    \n",
    "    fig = FF.create_trisurf(x=x,\n",
    "                        y=y, \n",
    "                        z=z, \n",
    "                        plot_edges=False,\n",
    "                        colormap=colormap,\n",
    "                        simplices=faces,\n",
    "                        backgroundcolor='rgb(64, 64, 64)',\n",
    "                        title=\"Interactive Visualization\")\n",
    "    iplot(fig)\n",
    "\n",
    "def plt_3d(verts, faces):\n",
    "    print(\"Drawing\")\n",
    "    x,y,z = zip(*verts) \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], linewidths=0.05, alpha=1)\n",
    "    face_color = [1, 1, 0.9]\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.set_xlim(0, max(x))\n",
    "    ax.set_ylim(0, max(y))\n",
    "    ax.set_zlim(0, max(z))\n",
    "    ax.set_facecolor((0.7, 0.7, 0.7))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "==================\n",
    "VERSION 1 - STATIC \n",
    "==================\n",
    "\n",
    "\n",
    "---> takes approx. 30 seconds\n",
    "\"\"\"\n",
    "\n",
    "v, f = make_mesh(imgs_after_resamp, 350)\n",
    "plt_3d(v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=======================\n",
    "VERSION 2 - INTERACTIVE \n",
    "=======================\n",
    "\n",
    "---> takes approx. 45 seconds (please ignore all the warnings)\n",
    "\"\"\"\n",
    "v, f = make_mesh(imgs_after_resamp, 350, 2)\n",
    "plotly_3d(v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
